purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(uM*dUB1))
}
if(z==4 || z==7 || z==10){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(nM*dNB1))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,0)
}
if(z==5 || z==9){
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(uM*dUB1))
#new flat
purchasedNewFlats <- c(purchasedNewFlats,0)
}
}
}
#purchased Flats
purchasedNewFlats <- c(0);
purchasedOldFlats <- c(0);
#money Status every month
moneyStatusMonthly <- c(10000000);
#prices
#new nM used uM
nM <- 990000
uM <- 560000
#discount for new
dNB1 <- 0.05
#discount for used
dUB1 <- 0.2
#flat value increase yearly
rVal <- 0.06
#price decrease every 4 years
lVal <- 0.08
#zakup mieszkań B1 rocznie
lN1 <- 4
lS1 <- 3
#years of investments
tY <- 45
for(i in 1:tY){
for(z in 1:12){
if(z==1){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(nM*dNB1))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(uM*dUB1))
}
if(z==4 || z==7 || z==10){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(nM*dNB1))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,0)
}
if(z==5 || z==9){
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(uM*dUB1))
#new flat
purchasedNewFlats <- c(purchasedNewFlats,0)
}
}
}
for(i in 1:tY){
for(z in 1:12){
if(z==1){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(nM*dNB1))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(uM*dUB1))
}
if(z==4 || z==7 || z==10){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(nM*dNB1))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,0)
}
if(z==5 || z==9){
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,moneyStatusMonthly-(uM*dUB1))
#new flat
purchasedNewFlats <- c(purchasedNewFlats,0)
}
}
}
#purchased Flats
purchasedNewFlats <- c(0);
purchasedOldFlats <- c(0);
#money Status every month
moneyStatusMonthly <- c(10000000);
#prices
#new nM used uM
nM <- 990000
uM <- 560000
#discount for new
dNB1 <- 0.05
#discount for used
dUB1 <- 0.2
#flat value increase yearly
rVal <- 0.06
#price decrease every 4 years
lVal <- 0.08
#zakup mieszkań B1 rocznie
lN1 <- 4
lS1 <- 3
#years of investments
tY <- 45
for(i in 1:tY){
for(z in 1:12){
if(z==1){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,(moneyStatusMonthly-(nM*dNB1)))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,(moneyStatusMonthly-(uM*dUB1)))
}
if(z==4 || z==7 || z==10){
#new flat
purchasedNewFlats <- c(purchasedNewFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,(moneyStatusMonthly-(nM*dNB1)))
#old flat
purchasedOldFlats <- c(purchasedOldFlats,0)
}
if(z==5 || z==9){
#old flat
purchasedOldFlats <- c(purchasedOldFlats,1)
#withdraw money from acount
moneyStatusMonthly <- c(moneyStatusMonthly,(moneyStatusMonthly-(uM*dUB1)))
#new flat
purchasedNewFlats <- c(purchasedNewFlats,0)
}
}
}
#13 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedDatasetRandomForest <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
setwd("~/Downloads/titanicData")
library(mice)
library(VIM)
library(SparseM)
#0 - reading data
dataset <- read.csv('titanicDataset.csv', header=TRUE)
workingData <- dataset
#1.1 Missing values
workingData[workingData == ""] <- NA
countNA <- as.data.frame(sapply(workingData, function(x) sum(is.na(x))))
#basic info about missing data for selected variables
md.pattern(workingData)
#more precise info about misisng data for variables
mice_plot <- aggr(workingData, col=c('blue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(workingData), cex.axis=.7,
gap=1, ylab=c("Missing data","Pattern"))
library(plyr)
library(ggplot2)
library(ggpubr)
# SEX - no missing data
#freq
sexStruct <- count(workingData, 'sex')
#female	466
#male	843
sexPercentages <- c()
for (row in 1:length(c(sexStruct$sex))) {
sexPercentages <- append(sexPercentages,round((sexStruct$freq[row]/sum(sexStruct$freq))*100,digits=2))
}
sexStruct$percentages <- as.data.frame(sexPercentages)
sexStruct <- sexStruct %>%
arrange(desc(sex)) %>%
mutate(pos = round(cumsum(sexPercentages) - 0.5*sexPercentages, digits = 2))
sexStruct
#bar graph for sex
ggplot(workingData, aes(sex)) +
geom_bar(fill = "#0073C2FF") +
theme_pubclean()
mycols <- c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF")
ggplot(sexStruct, aes(x = "", y = sexPercentages, fill = sex)) +
geom_bar(width = 1, stat = "identity", color = "white") +
coord_polar("y", start = 0)+
geom_text(aes(y = pos, label = sexPercentages), color = "white")+
scale_fill_manual(values = mycols) +
theme_void()
#PCLASS - nomissing data
#freq
pclassStruct <- count(workingData, 'pclass')
#1	323
#2	277
#3 709
pclassPercentages <- c()
for (row in 1:length(c(pclassStruct$pclass))) {
pclassPercentages <- append(pclassPercentages,round((pclassStruct$freq[row]/sum(pclassStruct$freq))*100,digits=2))
}
pclassStruct$percentages <- as.data.frame(pclassPercentages)
pclassStruct <- pclassStruct %>%
arrange(desc(pclass)) %>%
mutate(pos = round(cumsum(pclassPercentages) - 0.5*pclassPercentages, digits = 2))
pclassStruct
pclassStruct$pclass <- as.factor(pclassStruct$pclass)
#bar graph for pclass
ggplot(workingData, aes(pclass)) +
geom_bar(fill = c("#0073C2FF", "#EFC000FF", "#CD534CFF")) +
theme_pubclean()
mycols <- c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF")
ggplot(pclassStruct, aes(x = "", y = pclassPercentages, fill = pclass)) +
geom_bar(width = 1, stat = "identity", color = "white") +
coord_polar("y", start = 0)+
geom_text(aes(y = pos, label = pclassPercentages), color = "white")+
scale_fill_manual(values = mycols) +
theme_void()
#EMBARKED - 2 missing values -> skipping NA
#freq
embarkedStruct <- count(workingData, 'embarked')
embarkedPercentages <- c()
for (row in 1:length(c(embarkedStruct$embarked))) {
embarkedPercentages <- append(embarkedPercentages,round((embarkedStruct$freq[row]/sum(embarkedStruct$freq))*100,digits=2))
}
embarkedStruct$percentages <- as.data.frame(embarkedPercentages)
embarkedStruct <- embarkedStruct %>%
arrange(desc(embarked)) %>%
mutate(pos = round(cumsum(embarkedPercentages) - 0.5*embarkedPercentages, digits = 2))
embarkedStruct
#bar graph for embarked
ggplot(embarkedStruct, aes(embarked)) +
geom_bar(fill = c("#0073C2FF", "#EFC000FF", "#CD534CFF",'GREEN')) +
theme_pubclean()
mycols <- c("#0073C2FF", "#EFC000FF", "#868686FF")
ggplot(embarkedStruct, aes(x = "", y = embarkedPercentages, fill = embarked)) +
geom_bar(width = 1, stat = "identity", color = "black") +
coord_polar("y", start = 0)+
geom_text(aes(y = pos, label = embarkedPercentages), color = "white")+
scale_fill_manual(values = mycols) +
theme_void()
#2 - frequencies, percentages for survived
#freq
survivedStruct <- count(workingData, 'survived')
survivedPercentages <- c()
for (row in 1:length(c(survivedStruct$survived))) {
survivedPercentages <- append(survivedPercentages,round((survivedStruct$freq[row]/sum(survivedStruct$freq))*100,digits=2))
}
survivedStruct$percentages <- as.data.frame(survivedPercentages)
#4 - descriptive statistics for age
summary(workingData$age)
ageHist <- hist(workingData$age,
main="Histogram of titanic passengers' age",
xlab="Age",
ylab="Number of passengers",
col="red",
freq=TRUE
)
text(ageHist$mids,ageHist$counts,labels=ageHist$counts, adj=c(0.5, -0.5))
#4 - descriptive statistics for fare
summary(workingData$fare)
priceHist <- hist(workingData$fare,
main="Histogram of titanic ticket prices",
xlab="Fare value",
yLab="Number of tickets in specific price",
col="red",
freq=TRUE,
xlim=c(0,520)
)
text(priceHist$mids,priceHist$counts,labels=priceHist$counts, adj=c(0.5, -0.5))
attach(mtcars)
plot(workingData$age, workingData$fare, main="Age vs Price",
xlab="Age ", ylab="Price for ticket", pch=19, col='blue')
abline(lm(workingData$fare~workingData$age), col="red")
cor.test(workingData$age, workingData$fare, method="pearson")
#6 spliting for training and test set with seed
#ommiting rows with NA values in dataset
fullDataset <- na.omit(workingData)
require(caTools)
set.seed(123)
sample = sample.split(fullDataset,SplitRatio = 0.70)
trainingSet =subset(fullDataset,sample ==TRUE) #180 observations
testSet=subset(fullDataset, sample==FALSE) #90 observations
#freq
testSetSurvivedStruct <- count(testSet, 'survived')
testSetSurvivedPercentages <- c()
for (row in 1:length(c(testSetSurvivedStruct$survived))) {
testSetSurvivedPercentages <- append(testSetSurvivedPercentages,round((testSetSurvivedStruct$freq[row]/sum(testSetSurvivedStruct$freq))*100,digits=2))
}
testSetSurvivedStruct$percentages <- as.data.frame(testSetSurvivedPercentages)
#freq
trainingSetSurvivedStruct <- count(trainingSet, 'survived')
trainingSetSurvivedPercentages <- c()
for (row in 1:length(c(trainingSetSurvivedStruct$survived))) {
trainingSetSurvivedPercentages <- append(trainingSetSurvivedPercentages,round((trainingSetSurvivedStruct$freq[row]/sum(trainingSetSurvivedStruct$freq))*100,digits=2))
}
trainingSetSurvivedStruct$percentages <- as.data.frame(trainingSetSurvivedPercentages)
#BACK TO 6 -> spliting without ommitin NA rows
set.seed(123)
sampleProper = sample.split(workingData,SplitRatio = 0.70)
trainingSetProper =subset(workingData,sampleProper ==TRUE) #873 observations
testSetProper =subset(workingData, sampleProper==FALSE) #436 observations
#8 Replace missing values in Embarked with "S" for both sets
trainingSetProper$embarked[is.na(trainingSetProper$embarked)] <- "S"
testSetProper$embarked[is.na(testSetProper$embarked)] <- "S"
#9 -> before replacing duplicating datasets for A and B points
trainingSetProperA <- trainingSetProper
trainingSetProperB <- trainingSetProper
testSetProperA <- testSetProper
testSetProperB <- testSetProper
#9+10 A
#mean for age for full dataset
summary(workingData$age) #-> 29.881
#simple replace with mean for training and test set for Age values
trainingSetProperA$age[is.na(trainingSetProperA$age)] <- 29.8810
testSetProperA$age[is.na(testSetProperA$age)] <- 29.8810
#9+10 B
#USING HMISC IMPUTATION METHOD
install.packages("Hmisc")
install.packages("survival")
library(Hmisc)
library(survival)
#TRAINING SET
#preview for some NA values
head(trainingSetProperB$age, n=30)
#add new column with imputed values
trainingSetProperB$imputed_age <- with(trainingSetProperB, impute(age,median))
#check where it was imputed compare original with imputed in dataset
head(trainingSetProperB$imputed_age, n=30)
#TEST SET
#preview for some NA values
head(testSetProperB$age, n=30)
#add new column with imputed values
testSetProperB$imputed_age <- with(testSetProperB, impute(age,median))
#check where it was imputed compare original with imputed in dataset
head(testSetProperB$imputed_age, n=30)
#11 Setting Generalized Linear Model for Logit Regression with LOGIT link function
install.packages("tidyverse")
library(tidyverse)
selectedDatasetA <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedTestDatasetA <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
#replacing pclass for factors
selectedDatasetA$pclass[selectedDatasetA$pclass == 1] <- "first"
selectedDatasetA$pclass[selectedDatasetA$pclass == 2] <- "second"
selectedDatasetA$pclass[selectedDatasetA$pclass == 3] <- "third"
write.csv(selectedDatasetA, "trainingDatasetA", )
modelGLM <- glm(survived ~ .,family=binomial(link='logit'),data=selectedDatasetA)
#details of logistic regression
summary(modelGLM)
install.packages("pscl")
library(pscl)
#counting pseudo R2 to validate model fit
pR2(modelGLM) #McFadden pR2 > 0.3231 -> ~ 32% - very low
#measuring accuracy with test set
fitted.results <- predict(modelGLM,selectedTestDatasetA)
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != selectedTestDatasetA$survived)
print(paste('Accuracy',1-misClasificError))
#13 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedDatasetRandomForest <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
View(selectedDatasetRandomForest)
#make dependent variable categorical
selectedDatasetRandomForest$survived <- as.factor(selectedDatasetRandomForest$survived)
library(randomForest)
rForest <- randomForest(survived~.,data=selectedDatasetRandomForest)
print(rf)
rForest <- randomForest(survived~.,data=selectedDatasetRandomForest,ntree=500)
print(rf)
rForest <- randomForest(survived~.,data=selectedDatasetRandomForest,ntree=500)
library(randomForest)
rForest <- rf <- randomForest(
num ~ .,
data=selectedDatasetRandomForest
)
library(randomForest)
rForest <- rf <- randomForest(
survived ~ .,
data=selectedDatasetRandomForest
)
rForest
#error misclasified to total observations - 19.72%
#accuracy = 1-OOB => 80,28% => it's quite ok
#sensitivity => TP/(TP+FN) =>
SENS_RandomForest <- 263/(263+67)
SENS_RandomForest
#specificity => TN/(FP+TN)
SPEC_RandomForest <- 87/(19+87)
SPEC_RandomForest
require(pROC)
library(pROC)
install.packages("pROC")
require(pROC)
rForest.roc
rForest
pred1=predict(rForest,type = "prob")
predRandomForest=predict(rForest,type = "prob")
library(ROCR)
install.packages("ROCR")
library(ROCR)
performanceRandomForest = prediction(predRandomForest[,2], selectedDatasetRandomForest$survived)
aucRandomForest = performance(performanceRandomForest, "AUC")
predRandomForest=predict(rForest,type = "prob")
performanceRandomForest = prediction(predRandomForest[,2], selectedDatasetRandomForest$survived)
aucRandomForest = performance(performanceRandomForest, "AUC")
predRandomForest <- predict(rForest,type = "prob")
performanceRandomForest <- prediction(predRandomForest[,2], selectedDatasetRandomForest$survived)
aucRandomForest <- performance(performanceRandomForest, "AUC")
predRandomForest <- predict(rForest,type = "prob")
predRandomForest
performanceRandomForest <- prediction(predRandomForest[,2], selectedDatasetRandomForest$survived)
performanceRandomForest
aucRandomForest <- performance(performanceRandomForest, "AUC")
aucRandomForest <- performance(performanceRandomForest, "auc")
aucRandomForest
#True Positive and Negative Rate
predRandomForest2 = performance(performanceRandomForest, "tpr","fpr")
predRandomForest2
plot(predRandomForest2,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
#13 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
#13 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedTestDatasetRandomForest <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
#make dependent variable categorical
selectedDatasetRandomForest$survived <- as.factor(selectedDatasetRandomForest$survived)
library(randomForest)
rForest <- rf <- randomForest(
survived ~ .,
data=selectedDatasetRandomForest
)
rForest
#error misclasified to total observations - 19.72%
#accuracy = 1-OOB => 80,28% => it's quite ok
#sensitivity => TP/(TP+FN) => 0.7969 ~ 79,7% success in predicting the real survived cases -> Quite good
SENS_RandomForest <- 482/(482+135)
SENS_RandomForest
#specificity => TN/(FP+TN) => 0.820754 ~ 82% -> success in predicting real not survived cases => Quite good
SPEC_RandomForest <- 211/(45+211)
SPEC_RandomForest
prediction_for_roc_curve <- predict(rForest,selectedTestDatasetRandomForest$survived,type="prob")
prediction_for_roc_curve <- predict(rForest,selectedTestDatasetRandomForest,type="prob")
pretty_colours <- c("#F8766D","#00BA38","#619CFF")
pretty_colours <- c("#F8766D","#00BA38","#619CFF")
# Specify the different classes
classes <- levels(selectedTestDatasetRandomForest$survived)
# For each class
for (i in 1:3)
{
# Define which observations belong to class[i]
true_values <- ifelse(selectedTestDatasetRandomForest==classes[i],1,0)
# Assess the performance of classifier for class[i]
pred <- prediction(prediction_for_roc_curve[,i],true_values)
perf <- performance(pred, "tpr", "fpr")
if (i==1)
{
plot(perf,main="ROC Curve",col=pretty_colours[i])
}
else
{
plot(perf,main="ROC Curve",col=pretty_colours[i],add=TRUE)
}
# Calculate the AUC and print it to screen
auc.perf <- performance(pred, measure = "auc")
print(auc.perf@y.values)
}
print(aucRandomForest.values)
print(aucRandomForest)
print(aucRandomForest)
aucVal <- performance(predRandomForest2, measure = "auc")
aucVal <- performance(performanceRandomForest, measure = "auc")
aucVal
#details of logistic regression
summary(modelGLM)
#measuring accuracy with test set
fitted.results <- predict(modelGLM,selectedTestDatasetA)
fitted.results <- ifelse(fitted.results > 0.5,1,0)
modelGLM <- glm(survived ~ .,family=binomial(link='logit'),data=selectedDatasetA)
#details of logistic regression
summary(modelGLM)
#counting pseudo R2 to validate model fit
pR2(modelGLM) #McFadden pR2 > 0.3231 -> ~ 32% - very low
#measuring accuracy with test set
fitted.results <- predict(modelGLM,selectedTestDatasetA)
fitted.results <- ifelse(fitted.results > 0.5,1,0)
selectedTestDatasetA$pclass[selectedTestDatasetA$pclass == 1] <- "first"
selectedTestDatasetA$pclass[selectedTestDatasetA$pclass == 2] <- "second"
selectedTestDatasetA$pclass[selectedTestDatasetA$pclass == 3] <- "third"
#measuring accuracy with test set
fitted.results <- predict(modelGLM,selectedTestDatasetA)
fitted.results <- ifelse(fitted.results > 0.5,1,0)
#measuring accuracy with test set
fitted.results <- predict(modelGLM,selectedTestDatasetA)
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != selectedTestDatasetA$survived)
print(paste('Accuracy',1-misClasificError))
library(ROCR)
predictedGLM <- extract(fitted.results,selectedTestDatasetA)
