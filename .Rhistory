#male	843
sexPercentages <- c()
for (row in 1:length(c(sexStruct$sex))) {
sexPercentages <- append(sexPercentages,round((sexStruct$freq[row]/sum(sexStruct$freq))*100,digits=2))
}
sexStruct$percentages <- as.data.frame(sexPercentages)
sexStruct <- sexStruct %>%
arrange(desc(sex)) %>%
mutate(pos = round(cumsum(sexPercentages) - 0.5*sexPercentages, digits = 2))
sexStruct
#bar graph for sex
ggplot(workingData, aes(sex)) +
geom_bar(fill = "#0073C2FF") +
theme_pubclean()
mycols <- c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF")
ggplot(sexStruct, aes(x = "", y = sexPercentages, fill = sex)) +
geom_bar(width = 1, stat = "identity", color = "white") +
coord_polar("y", start = 0)+
geom_text(aes(y = pos, label = sexPercentages), color = "white")+
scale_fill_manual(values = mycols) +
theme_void()
#PCLASS - nomissing data
#freq
pclassStruct <- count(workingData, 'pclass')
#1	323
#2	277
#3 709
pclassPercentages <- c()
for (row in 1:length(c(pclassStruct$pclass))) {
pclassPercentages <- append(pclassPercentages,round((pclassStruct$freq[row]/sum(pclassStruct$freq))*100,digits=2))
}
pclassStruct$percentages <- as.data.frame(pclassPercentages)
pclassStruct <- pclassStruct %>%
arrange(desc(pclass)) %>%
mutate(pos = round(cumsum(pclassPercentages) - 0.5*pclassPercentages, digits = 2))
pclassStruct
pclassStruct$pclass <- as.factor(pclassStruct$pclass)
#bar graph for pclass
ggplot(workingData, aes(pclass)) +
geom_bar(fill = c("#0073C2FF", "#EFC000FF", "#CD534CFF")) +
theme_pubclean()
mycols <- c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF")
ggplot(pclassStruct, aes(x = "", y = pclassPercentages, fill = pclass)) +
geom_bar(width = 1, stat = "identity", color = "white") +
coord_polar("y", start = 0)+
geom_text(aes(y = pos, label = pclassPercentages), color = "white")+
scale_fill_manual(values = mycols) +
theme_void()
#EMBARKED - 2 missing values -> skipping NA
#freq
embarkedStruct <- count(workingData, 'embarked')
embarkedPercentages <- c()
for (row in 1:length(c(embarkedStruct$embarked))) {
embarkedPercentages <- append(embarkedPercentages,round((embarkedStruct$freq[row]/sum(embarkedStruct$freq))*100,digits=2))
}
embarkedStruct$percentages <- as.data.frame(embarkedPercentages)
embarkedStruct <- embarkedStruct %>%
arrange(desc(embarked)) %>%
mutate(pos = round(cumsum(embarkedPercentages) - 0.5*embarkedPercentages, digits = 2))
embarkedStruct
#bar graph for embarked
ggplot(embarkedStruct, aes(embarked)) +
geom_bar(fill = c("#0073C2FF", "#EFC000FF", "#CD534CFF",'GREEN')) +
theme_pubclean()
mycols <- c("#0073C2FF", "#EFC000FF", "#868686FF")
ggplot(embarkedStruct, aes(x = "", y = embarkedPercentages, fill = embarked)) +
geom_bar(width = 1, stat = "identity", color = "black") +
coord_polar("y", start = 0)+
geom_text(aes(y = pos, label = embarkedPercentages), color = "white")+
scale_fill_manual(values = mycols) +
theme_void()
#2 - frequencies, percentages for survived
#freq
survivedStruct <- count(workingData, 'survived')
survivedPercentages <- c()
for (row in 1:length(c(survivedStruct$survived))) {
survivedPercentages <- append(survivedPercentages,round((survivedStruct$freq[row]/sum(survivedStruct$freq))*100,digits=2))
}
survivedStruct$percentages <- as.data.frame(survivedPercentages)
#4 - descriptive statistics for age
summary(workingData$age)
ageHist <- hist(workingData$age,
main="Histogram of titanic passengers' age",
xlab="Age",
ylab="Number of passengers",
col="red",
freq=TRUE
)
text(ageHist$mids,ageHist$counts,labels=ageHist$counts, adj=c(0.5, -0.5))
#4 - descriptive statistics for fare
summary(workingData$fare)
priceHist <- hist(workingData$fare,
main="Histogram of titanic ticket prices",
xlab="Fare value",
yLab="Number of tickets in specific price",
col="red",
freq=TRUE,
xlim=c(0,520)
)
text(priceHist$mids,priceHist$counts,labels=priceHist$counts, adj=c(0.5, -0.5))
attach(mtcars)
plot(workingData$age, workingData$fare, main="Age vs Price",
xlab="Age ", ylab="Price for ticket", pch=19, col='blue')
abline(lm(workingData$fare~workingData$age), col="red")
cor.test(workingData$age, workingData$fare, method="pearson")
#6 spliting for training and test set with seed
#ommiting rows with NA values in dataset
fullDataset <- na.omit(workingData)
require(caTools)
set.seed(123)
sample = sample.split(fullDataset,SplitRatio = 0.70)
trainingSet =subset(fullDataset,sample ==TRUE) #180 observations
testSet=subset(fullDataset, sample==FALSE) #90 observations
#freq
testSetSurvivedStruct <- count(testSet, 'survived')
testSetSurvivedPercentages <- c()
for (row in 1:length(c(testSetSurvivedStruct$survived))) {
testSetSurvivedPercentages <- append(testSetSurvivedPercentages,round((testSetSurvivedStruct$freq[row]/sum(testSetSurvivedStruct$freq))*100,digits=2))
}
testSetSurvivedStruct$percentages <- as.data.frame(testSetSurvivedPercentages)
#freq
trainingSetSurvivedStruct <- count(trainingSet, 'survived')
trainingSetSurvivedPercentages <- c()
for (row in 1:length(c(trainingSetSurvivedStruct$survived))) {
trainingSetSurvivedPercentages <- append(trainingSetSurvivedPercentages,round((trainingSetSurvivedStruct$freq[row]/sum(trainingSetSurvivedStruct$freq))*100,digits=2))
}
trainingSetSurvivedStruct$percentages <- as.data.frame(trainingSetSurvivedPercentages)
#BACK TO 6 -> spliting without ommitin NA rows
set.seed(123)
sampleProper = sample.split(workingData,SplitRatio = 0.70)
trainingSetProper =subset(workingData,sampleProper ==TRUE) #873 observations
testSetProper =subset(workingData, sampleProper==FALSE) #436 observations
#8 Replace missing values in Embarked with "S" for both sets
trainingSetProper$embarked[is.na(trainingSetProper$embarked)] <- "S"
testSetProper$embarked[is.na(testSetProper$embarked)] <- "S"
#9 -> before replacing duplicating datasets for A and B points
trainingSetProperA <- trainingSetProper
trainingSetProperB <- trainingSetProper
testSetProperA <- testSetProper
testSetProperB <- testSetProper
#9+10 A
#mean for age for full dataset
summary(workingData$age) #-> 29.881
#simple replace with mean for training and test set for Age values
trainingSetProperA$age[is.na(trainingSetProperA$age)] <- 29.8810
testSetProperA$age[is.na(testSetProperA$age)] <- 29.8810
#9+10 B
#USING HMISC IMPUTATION METHOD
install.packages("Hmisc")
library(Hmisc)
library(survival)
#TRAINING SET
#preview for some NA values
head(trainingSetProperB$age, n=30)
#add new column with imputed values
trainingSetProperB$imputed_age <- with(trainingSetProperB, impute(age,median))
#check where it was imputed compare original with imputed in dataset
head(trainingSetProperB$imputed_age, n=30)
#TEST SET
#preview for some NA values
head(testSetProperB$age, n=30)
#add new column with imputed values
testSetProperB$imputed_age <- with(testSetProperB, impute(age,median))
#check where it was imputed compare original with imputed in dataset
head(testSetProperB$imputed_age, n=30)
library(tidyverse)
selectedDatasetA <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedTestDatasetA <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
#replacing pclass for factors
selectedDatasetA$pclass[selectedDatasetA$pclass == 1] <- "first"
selectedDatasetA$pclass[selectedDatasetA$pclass == 2] <- "second"
selectedDatasetA$pclass[selectedDatasetA$pclass == 3] <- "third"
selectedTestDatasetA$pclass[selectedTestDatasetA$pclass == 1] <- "first"
selectedTestDatasetA$pclass[selectedTestDatasetA$pclass == 2] <- "second"
selectedTestDatasetA$pclass[selectedTestDatasetA$pclass == 3] <- "third"
write.csv(selectedDatasetA, "trainingDatasetA", )
modelGLM <- glm(formula = survived ~ .,family=binomial,data=selectedDatasetA)
#predicted probability, response - gives probabilities in one vector
pred_probability <- predict(modelGLM, type = 'response', newdata = selectedTestDatasetA[-5])
pred_probability
#vector of predicted values for chance of survival 1- yes 0 - no
predY_A <- ifelse(pred_probability > 0.5, 1, 0)
predY_A
#add column to testSet to visualy verify succesfull prdictions by comparing records from the dataset
selectedTestDatasetA$predictedGLM <- predY_A
View(selectedTestDatasetA)
#details of logistic regression
summary(modelGLM)
#confusion matrix
confMatrixGLM <- table(selectedTestDatasetA$survived,predY_A)
confMatrixGLM
#sensitivity => TP/(TP+FN) => 0.7811 ~ 78% success in predicting the real survived cases -> Quite good
SENS_GLM <- 110/(110+46)
SENS_GLM
#specificity => TN/(FP+TN) => 0.82421 ~ 82% -> success in predicting real not survived cases => Quite good
SPEC_GLM <- 236/(44+236)
SPEC_GLM
#visualisation
install.packages('ElemStatLearn')
#accuracy => (TP + TN) / (TP + TN + FP + FN)
ACC_GLM = (110 + 236) / (110 + 236 + 44 + 46)
ACC_GLM
#ROC
library(pROC)
#predicted probability, response - gives probabilities in one vector
pred_probability <- predict(modelGLM, type = 'response', newdata = selectedTestDatasetA[1:3])
#predicted probability, response - gives probabilities in one vector
pred_probability <- predict(modelGLM, type = 'response', newdata = selectedTestDatasetA[1:4])
#set of all probabilities for each record in test dataset
pred_probability
#vector of predicted values for chance of survival 1- yes 0 - no
predY_A <- ifelse(pred_probability > 0.5, 1, 0)
predY_A
#add column to testSet to visualy verify succesfull prdictions by comparing records from the dataset
selectedTestDatasetA$predictedGLM <- predY_A
#confusion matrix
confMatrixGLM <- table(selectedTestDatasetA$survived,predY_A)
confMatrixGLM
#accuracy => (TP + TN) / (TP + TN + FP + FN) => 0.793578 ~ 79,4% success in predicting survived cases
ACC_GLM = (110 + 236) / (110 + 236 + 44 + 46)
ACC_GLM
#sensitivity => TP/(TP+FN) => 0.7051282 ~ 70,5% success in predicting the real survived cases -> Quite ok
SENS_GLM <- 110/(110+46)
SENS_GLM
#specificity => TN/(FP+TN) => 0.8428571 ~ 84,2% -> success in predicting real not survived cases => Quite good
SPEC_GLM <- 236/(44+236)
SPEC_GLM
#ROC
library(pROC)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:4])
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5])
plot(g)
plot(gGLM)
#AUC
performanceGLM <- performance(pred_probability, measure = "tpr", x.measure = "fpr")
aucGLM <- performance(pred_probability, "auc")
library(ROCR)
aucGLM <- performance(pred_probability, "auc")
#AUC
predGLM <- prediction(pred_probability, selectedTestDatasetA$survived)
aucGLM <- performance(predGLM, "auc")
aucGLM
print(aucGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], print.auc = TRUE)
plot(gGLM)
lines.roc()
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], print.auc = TRUE, ylab="True positive percentage", xlab="False positive percentage")
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], print.auc = TRUE, ylab="True positive percentage", xlab="False positive percentage")
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], ylab="True positive percentage", xlab="False positive percentage")
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], ylab="True positive percentage", xlab="False positive percentage")
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], auc=TRUE")
plot(gGLM)
#visualisation
install.packages('ElemStatLearn')
library(ElemStatLearn)
#Along with increase of age by 1 year the chances of survival are decreasing by 4.101 times ceteris paribus
#Changes of survival for men were 13.512 times smaller than for female ceteris paribus
#Chances of survival for passengers traveling in the second class were 3.930 times smaller than for passengers traveling in first class ceteris paribus
#Chances of survival for pasengers traveling in third class were 7,603 smaller than for passengers traveling first class ceteris paribus
install.packages("pscl")
library(pscl)
#12
#counting pseudo R2 to validate model fit
pR2(modelGLM) #McFadden pR2 > 0.3231 -> ~ 32% - very low
library(ROCR)
#measuring accuracy with test set
fitted.results <- predict(modelGLM,selectedTestDatasetA)
fitted.results <- ifelse(fitted.results > 0.5,1,0)
misClasificError <- mean(fitted.results != selectedTestDatasetA$survived)
print(paste('Accuracy',1-misClasificError))
"Accuracy 0.793577" # => 0.79355 => 79.35% success prediction for testSet
#13 & 14 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedTestDatasetRandomForest <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
#make dependent variable categorical
selectedDatasetRandomForest$survived <- as.factor(selectedDatasetRandomForest$survived)
#random forest classification
library(randomForest)
rForest <- rf <- randomForest(
survived ~ .,
data=selectedDatasetRandomForest
)
rForest
#results
#OOB estimate of  error rate: 20.62%
#Confusion matrix:
#  0   1 class.error
#0 482  45  0.08538899
#1 135 211  0.39017341
#error misclasified to total observations - 19.72%
#accuracy = 1-OOB => 80,28% => it's quite ok
#sensitivity => TP/(TP+FN) => 0.7811 ~ 78% success in predicting the real survived cases -> Quite good
SENS_RandomForest <- 482/(482+135)
SENS_RandomForest
#specificity => TN/(FP+TN) => 0.82421 ~ 82% -> success in predicting real not survived cases => Quite good
SPEC_RandomForest <- 211/(45+211)
SPEC_RandomForest
predRandomForest <- predict(rForest,type = "prob")
install.packages("ROCR")
library(ROCR)
performanceRandomForest <- prediction(predRandomForest[,2], selectedDatasetRandomForest$survived)
aucRandomForest <- performance(performanceRandomForest, "auc")
#True Positive and Negative Rate
predRandomForest2 = performance(performanceRandomForest, "tpr","fpr")
plot(predRandomForest2,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
install.packages("ROCR")
install.packages("ROCR")
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], auc =TRUE)
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], auc())
plot(gGLM)
#ROC
library(pROC)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], auc())
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], auc = TRUE)
plot(gGLM)
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, auc = TRUE, data = selectedTestDatasetA[1:5])
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, auc = TRUE, data = selectedTestDatasetA[1:5])
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5])
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], xlab("False positive percentage"))
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], xlab("False positive percentage"))
plot(gGLM)
gGLM <- roc(survived ~ pred_probability, data = selectedTestDatasetA[1:5], print.auc = TRUE)
plot(gGLM)
#AUC
#fprGLM = fp / (fp + tn)
fprGLM = 44/(44+236)
#tprGLM = tp / (tp + fn)
tprGLM = 110 / (110 + 46)
aucGLM = auc(fprGLM, tprGLM)
aucGLM = auc(fprGLM, tprGLM, auc = TRUE
aucGLM = auc(fprGLM, tprGLM, auc = TRUE)
aucGLM
library(pROC)
roc
roc()
roc_(auc)
roc(auc)
gGLM
#AUC => 0.8462
plot(gGLM, print.auc = TRUE)
#AUC => 0.8462
plot(gGLM, print.auc = TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage")
precisionGLM <- SENS_GLM
recallGLM <- SENS_GLM
precisionGLM <- 110/(110+44)
#F1 = 2((precision x recall)/(precision + recall))
F1ScoreGLM <- 2((precisionGLM*recallGLM)/(precisionGLM+recallGLM))
#F1 = 2((precision x recall)/(precision + recall))
F1ScoreGLM <- 2*((precisionGLM*recallGLM)/(precisionGLM+recallGLM))
F1ScoreGLM
#details of logistic regression
summary(modelGLM)
#Ginie Score  (2*AUC)-1
ginieGLM <- (2*0.8462)-1
ginieGLM
#counting pseudo R2 to validate model fit
pR2(modelGLM) #McFadden pR2 > 0.3231 -> ~ 32% - very low
library(pscl)
#counting pseudo R2 to validate model fit
pR2(modelGLM) #McFadden pR2 > 0.3231 -> ~ 32% - very low
#13 & 14 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
library(tidyverse)
#13 & 14 Random forrest
selectedDatasetRandomForest <- trainingSetProperA %>% select('age','sex','pclass','embarked','survived')
selectedTestDatasetRandomForest <- testSetProperA %>% select('age','sex','pclass','embarked','survived')
#make dependent variable categorical
selectedDatasetRandomForest$survived <- as.factor(selectedDatasetRandomForest$survived)
#error misclasified to total observations - 19.72%
#accuracy = 1-OOB => 80,28% => it's quite ok
#accuracy => (TP + TN) / (TP + TN + FP + FN) => 0.793578 ~ 79,4% success in predicting survived cases
ACC_GLM = (211 + 482) / (211 + 482 + 45 + 135)
#error misclasified to total observations - 19.72%
#accuracy = 1-OOB => 80,28% => it's quite ok
#accuracy => (TP + TN) / (TP + TN + FP + FN) => 0.793578 ~ 79,4% success in predicting survived cases
ACC_RF = (211 + 482) / (211 + 482 + 45 + 135)
ACC_RF
#sensitivity => TP/(TP+FN) => 0.7811 ~ 78% success in predicting the real survived cases -> Quite good
SENS_RandomForest <- 211/(211+135)
SENS_RandomForest
#specificity => TN/(FP+TN) => 0.82421 ~ 82% -> success in predicting real not survived cases => Quite good
SPEC_RandomForest <- 482/(45+482)
SPEC_RandomForest
rForest <- rf <- randomForest(
survived ~ .,
data=selectedDatasetRandomForest
)
library(randomForest)
rForest <- rf <- randomForest(
survived ~ .,
data=selectedDatasetRandomForest
)
rForest
predRandomForest <- predict(rForest,type = "prob")
library(ROCR)
performanceRandomForest <- prediction(predRandomForest[,2], selectedDatasetRandomForest$survived)
aucRandomForest <- performance(performanceRandomForest, "auc")
aucRandomForest
#True Positive and Negative Rate
predRandomForest2 = performance(performanceRandomForest, "tpr","fpr")
plot(predRandomForest2,main="ROC Curve for Random Forest",col=2,lwd=2,auc=TRUE)
plot(predRandomForest2,main="ROC Curve for Random Forest",col=2,lwd=2,print.auc = TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage")
predRandomForest2
View(selectedTestDatasetRandomForest)
predictionRF <- predict(rForest, newdata = selectedTestDatasetRandomForest[1:4])
confMatrixRF <- table(selectedTestDatasetRandomForest$survived,predictionRF)
confMatrixRF
#accuracy => (TP + TN) / (TP + TN + FP + FN) => 0.7938144 ~ 79,4% success in predicting survived cases => very simillar to GLM model
ACC_RFTest = (94 + 260) / (94 + 260 + 22 + 60)
ACC_RFTest
#sensitivity => TP/(TP+FN) => 0.6098266 ~ 60,9% success in predicting the real survived cases -> Lower success rate than in case of GLM
SENS_RFTest <- 94/(94+22)
SENS_RFTest
#specificity => TN/(FP+TN) => 0.914611 ~ 91,4% -> the success in predicting real not survived cases is better for Random Forest than for GLM
SPEC_RFTest <- 260/(60+260)
SPEC_RFTest
library(pROC)
#vector of predicted values for chance of survival 1- yes 0 - no
predRF <- ifelse(predictionRF > 0.5, 1, 0)
predictionRF
#add column to testSet to visualy verify succesfull prdictions by comparing records from the dataset
selectedTestDatasetRandomForest$predictedRF <- predictionRF
#AUC + ROC
gRandomForest <- roc(survived ~ predictionRF, data = selectedTestDatasetRandomForest[1:5])
#AUC + ROC
predRF2 <- predict(rForest, type = 'response', newdata = selectedTestDatasetRandomForest[1:4])
gRandomForest <- roc(survived ~ predRF2, data = selectedTestDatasetRandomForest[1:5])
gRandomForest
gRandomForest <- roc(survived, data = selectedTestDatasetRandomForest[1:5])
gRandomForest <- roc(selectedTestDatasetRandomForest$survived, data = selectedTestDatasetRandomForest[1:5])
gRandomForest <- roc(selectedTestDatasetRandomForest$survived, data = selectedTestDatasetRandomForest)
#AUC + ROC
predRF2 <- predict(rForest, type = 'response', newdata = selectedTestDatasetRandomForest[1:4])
gRandomForest <- roc(predRF2, data = selectedTestDatasetRandomForest)
#AUC + ROC
gRandomForest <- roc(survived ~ predictionRF, data = selectedTestDatasetRandomForest[1:5])
#AUC + ROC
gRandomForest <- roc(survived ~ predictionRF, selectedTestDatasetRandomForest$survived)
#AUC => 0.8462 >0.5 => 84.6%
plot(predictionRF, print.auc = TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage")
#AUC + ROC
predictionRF2 <- predict(rForest, newdata = selectedTestDatasetRandomForest[1:4], type = 'prob')
gRandomForest <- roc(survived ~ predictionRF2)
gRandomForest <- roc(selectedTestDatasetRandomForest$survived ~ predictionRF2)
gRandomForest <- roc(as.numeric(selectedTestDatasetRandomForest$survived) ~ predictionRF2)
gRandomForest
gRandomForest <- roc(as.numeric(selectedTestDatasetRandomForest$survived),predictionRF2[,2])
gRandomForest
predictionRF2
gRandomForest
#AUC => 0.8436 >0.5 => 84.36%
plot(gRandomForest, print.auc = TRUE, xlab="False Positive Percentage", ylab="True Positive Percentage")
#Ginie Score  (2*AUC)-1 => 0.6924 ~ in 69% the model is perfect
ginieRF <- (2*0.8436)-1
ginieRF
precisionRF <- 94/(94+22)
recallGLM <- SENS_RandomForest
recallRF <- SENS_RandomForest
#F1 = 2((precision x recall)/(precision + recall))
F1ScoreRF <- 2*((precisionRF*recallRF)/(precisionRF+recallRF))
F1ScoreRF
summary(rForest)
rForest$oob.times
rForest$call
rForest$type
rForest$predicted
rForest$classes
rForest$importance
rForest$importanceSD
rForest$localImportance
rForest$proximity
rForest$ntree
rForest$mtry
rForest$forest
rForest$y
rForest$test
rForest$inbag
rForest$terms
#F1 = 2((precision x recall)/(precision + recall))
F1ScoreRF <- 2*((precisionRF*recallRF)/(precisionRF+recallRF))
F1ScoreRF
#simple linear regression using general linear model
modelGLM <- glm(formula = survived ~ .,family=binomial,data=selectedDatasetA)
#details of logistic regression
summary(modelGLM)
#predicted probability, response - gives probabilities in one vector
pred_probability <- predict(modelGLM, type = 'response', newdata = selectedTestDatasetA[1:4])
#set of all probabilities for each record in test dataset
pred_probability
#vector of predicted values for chance of survival 1- yes 0 - no
predY_A <- ifelse(pred_probability > 0.5, 1, 0)
predY_A
#add column to testSet to visualy verify succesfull prdictions by comparing records from the dataset
selectedTestDatasetA$predictedGLM <- predY_A
write.csv(selectedTestDatasetA, "predictedTestDatasetGLM", )
write.csv(selectedTestDatasetA, "predictedTestDatasetGLM", )
setwd("~/Downloads/titanicData")
write.csv(selectedTestDatasetA, "predictedTestDatasetGLM.csv", )
#add column to testSet to visualy verify succesfull prdictions by comparing records from the dataset
selectedTestDatasetA$predictedGLM <- predY_A
write.csv(selectedTestDatasetA, "predictedTestDatasetGLM.csv", )
